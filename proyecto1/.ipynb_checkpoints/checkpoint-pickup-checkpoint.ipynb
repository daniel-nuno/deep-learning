{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6001f22e",
   "metadata": {},
   "source": [
    "Check-point file\n",
    "\n",
    "Load training and validation list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d12519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import AUTOTUNE\n",
    "\n",
    "#from tensorflow_addons.losses import GIoULoss\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28daf417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('training_list.data', 'rb') as filehandle:\n",
    "    # Store the data as a binary data stream\n",
    "    training_list = pickle.load(filehandle)\n",
    "\n",
    "with open('validation_list.data', 'rb') as filehandle:\n",
    "    # Store the data as a binary data stream\n",
    "    validation_list = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f5875",
   "metadata": {},
   "source": [
    "Load dataset and error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34bd4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_element(element):\n",
    "    #make tensors list delimited by ,\n",
    "    element = tf.strings.split(element, sep=\",\")\n",
    "    #load image\n",
    "    img = tf.io.read_file(element[0])\n",
    "    #make sure is 3 channels\n",
    "    #the pretrained model requires [0,255] values\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    #conver to float [0,1)\n",
    "    #img = tf.image.convert_image_dtype(img, dtype=tf.float16)\n",
    "    #resize\n",
    "    img = tf.image.resize(img, (128, 128))\n",
    "    #category\n",
    "    #category = tf.constant(element[1])\n",
    "    category =tf.strings.to_number(element[1], tf.int32)\n",
    "    #bounding box\n",
    "    x_min = tf.strings.to_number(element[2])\n",
    "    y_min = tf.strings.to_number(element[3])\n",
    "    x_max = tf.strings.to_number(element[4])\n",
    "    y_max = tf.strings.to_number(element[5])\n",
    "    bb = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "    labels = {'class_output': category, 'box_output':bb}\n",
    "\n",
    "    return (img, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbad39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_list)\n",
    "train_dataset = (train_dataset\n",
    "                 .shuffle(len(training_list))\n",
    "                 .map(load_element, num_parallel_calls=AUTOTUNE)\n",
    "                 .cache()\n",
    "                 .batch(bath_size)\n",
    "                 .prefetch(AUTOTUNE)\n",
    "                 )\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(validation_list)\n",
    "val_dataset = (val_dataset\n",
    "                 .shuffle(len(validation_list))\n",
    "                 .map(load_element, num_parallel_calls = AUTOTUNE)\n",
    "                 .cache()\n",
    "                 .batch(bath_size)\n",
    "                 .prefetch(AUTOTUNE)\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f12d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GIoU(bb_true, bb_pred):\n",
    "    #make zero as tensor\n",
    "    zero = tf.convert_to_tensor(0.0, bb_true.dtype)\n",
    "    #convert them to tensor clases\n",
    "    Ax1, Ay1, Ax2, Ay2 = tf.unstack(bb_true, 4, axis=-1)\n",
    "    Bx1, By1, Bx2, By2 = tf.unstack(bb_pred, 4, axis=-1)\n",
    "\n",
    "    #for the bounding box predicted make sure Bx2 > Bx1 y By2 > By1\n",
    "    bx1 = tf.math.minimum(Bx1, Bx2)\n",
    "    by1 = tf.math.minimum(By1, By2)\n",
    "    bx2 = tf.math.maximum(Bx1, Bx2)\n",
    "    by2 = tf.math.maximum(By1, By2)\n",
    "\n",
    "    #calculate area of true bounding box\n",
    "    A_area = (Ax2 - Ax1)*(Ay2 - Ay1)\n",
    "    #calculate area of predicted bounding box\n",
    "    B_area = (bx2 - bx1)*(by2 - by1)\n",
    "    \n",
    "    #calculate intersection over true and pred\n",
    "    #find the box overlaps both boxes\n",
    "    #each inter calculates the smallest stride\n",
    "    x_inter_1 = tf.math.maximum(bx1, Ax1)\n",
    "    y_inter_1 = tf.math.maximum(by1, Ay1)\n",
    "    x_inter_2 = tf.math.minimum(bx2, Ax2)\n",
    "    y_inter_2 = tf.math.minimum(by2, Ay2)\n",
    "    #get width\n",
    "    w_inter = tf.maximum(zero, x_inter_1 - x_inter_2)\n",
    "    #get height\n",
    "    h_inter = tf.maximum(zero, y_inter_1 - y_inter_2)\n",
    "    #intersection\n",
    "    I = w_inter * h_inter\n",
    "    #area over union\n",
    "    area_union = (B_area + A_area) - I\n",
    "    iou = tf.math.divide_no_nan(I, area_union)\n",
    "\n",
    "    #find the b box C smaller that surrounding/fits both A and B\n",
    "    Cx1 = tf.math.minimum(bx1, Ax1)\n",
    "    Cy1 = tf.math.minimum(by1, Ay1)\n",
    "    Cx2 = tf.math.maximum(bx2, Ax2)\n",
    "    Cy2 = tf.math.maximum(by2, Ay2)\n",
    "\n",
    "    #calculate the C area\n",
    "    C_area = (Cx2 - Cx1) * (Cy2 - Cy1)\n",
    "    #calculate giou\n",
    "    giou = iou - tf.math.divide_no_nan(C_area - area_union, C_area)\n",
    "    #calculate mean of all observations\n",
    "    m_giou = tf.reduce_mean(giou, axis=0)\n",
    "\n",
    "    return m_giou\n",
    "\n",
    "def my_GIoULoss(bb_true, bb_pred):\n",
    "    return 1.0 - my_GIoU(bb_true, bb_pred)\n",
    "\n",
    "def my_sparse_category_accurary(y_true, y_pred):\n",
    "    #y_true is expected to be integer\n",
    "    #y_pred is a numpy.ndarray with the normalized probabilities\n",
    "    acc = np.dot(1, np.not_equal(y_true, np.argmax(y_pred, axis=1)))\n",
    "    return acc\n",
    "\n",
    "def my_IoU_np(y_true, y_pred):\n",
    "    #becausse model predict returns a numpy.ndarray then convert to tensors because the function already works as tensors\n",
    "    bb_true = tf.convert_to_tensor(y_true, y_true.dtype)\n",
    "    bb_pred = tf.convert_to_tensor(y_pred, y_pred.dtype)\n",
    "\n",
    "    #make zero as tensor\n",
    "    zero = tf.convert_to_tensor(0.0, bb_true.dtype)\n",
    "    #convert them to tensor clases\n",
    "    Ax1, Ay1, Ax2, Ay2 = tf.unstack(bb_true, 4, axis=-1)\n",
    "    Bx1, By1, Bx2, By2 = tf.unstack(bb_pred, 4, axis=-1)\n",
    "\n",
    "    #for the bounding box predicted make sure Bx2 > Bx1 y By2 > By1\n",
    "    bx1 = tf.math.minimum(Bx1, Bx2)\n",
    "    by1 = tf.math.minimum(By1, By2)\n",
    "    bx2 = tf.math.maximum(Bx1, Bx2)\n",
    "    by2 = tf.math.maximum(By1, By2)\n",
    "\n",
    "    #calculate area of true bounding box\n",
    "    A_area = (Ax2 - Ax1)*(Ay2 - Ay1)\n",
    "    #calculate area of predicted bounding box\n",
    "    B_area = (bx2 - bx1)*(by2 - by1)\n",
    "    \n",
    "    #calculate intersection over true and pred\n",
    "    #find the box overlaps both boxes\n",
    "    #each inter calculates the smallest stride\n",
    "    x_inter_1 = tf.math.maximum(bx1, Ax1)\n",
    "    y_inter_1 = tf.math.maximum(by1, Ay1)\n",
    "    x_inter_2 = tf.math.minimum(bx2, Ax2)\n",
    "    y_inter_2 = tf.math.minimum(by2, Ay2)\n",
    "    #get width\n",
    "    w_inter = tf.maximum(zero, x_inter_1 - x_inter_2)\n",
    "    #get height\n",
    "    h_inter = tf.maximum(zero, y_inter_1 - y_inter_2)\n",
    "    #intersection\n",
    "    I = w_inter * h_inter\n",
    "    #area over union\n",
    "    area_union = (B_area + A_area) - I\n",
    "    iou = tf.math.divide_no_nan(I, area_union)\n",
    "\n",
    "    #convert back to numpy\n",
    "    iou = iou.numpy()\n",
    "    #check if is over 50% then 0 otherwise 1\n",
    "    over_50 = np.where(iou>0.5, 0, 1)\n",
    "\n",
    "    return over_50\n",
    "\n",
    "def custom_error(y_true_cat, y_pred_cat, y_true_bb, y_pred_bb):\n",
    "    d = my_sparse_category_accurary(y_true_cat, y_pred_cat)\n",
    "    f = my_IoU_np(y_true_bb, y_pred_bb)\n",
    "    e = np.max(np.column_stack((d,f)), axis=1)\n",
    "    return e, e.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8c5ea",
   "metadata": {},
   "source": [
    "Load model and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc2b95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetV2M(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=Input(shape=(128,128,3)),\n",
    "    pooling=None,\n",
    "    include_preprocessing=True)\n",
    "\n",
    "base_model.trainable=False\n",
    "base_model_output = base_model.output\n",
    "\n",
    "no_of_classes = 200\n",
    "\n",
    "# We could also use Flatten()(x) but GAP is more effective, it reduces \n",
    "# Parameters and controls overfitting.\n",
    "flattened_output = GlobalAveragePooling2D()(base_model_output)\n",
    "#flattened_output = Flatten()(base_model_output)\n",
    "\n",
    "# Create our Classification Head, final layer contains \n",
    "# Ouput units = no. classes\n",
    "class_prediction = Dense(256, activation=\"relu\")(flattened_output)\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "#class_prediction = Dropout(0.2)(class_prediction)\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "class_prediction = Dropout(0.2)(class_prediction )\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "class_prediction = Dense(no_of_classes, activation='softmax',name=\"class_output\")(class_prediction)\n",
    "\n",
    "# Create Our Localization Head, final layer contains 4 nodes for x1,y1,x2,y2\n",
    "# Respectively.\n",
    "box_output = Dense(256, activation=\"relu\")(flattened_output)\n",
    "box_output = Dense(128, activation=\"relu\")(box_output)\n",
    "box_output = Dropout(0.2)(box_output)\n",
    "box_output = Dense(64, activation=\"relu\")(box_output)\n",
    "box_output = Dropout(0.2)(box_output)\n",
    "box_output = Dense(32, activation=\"relu\")(box_output)\n",
    "box_predictions = Dense(4, activation='sigmoid', name= \"box_output\")(box_output)\n",
    "\n",
    "# Now combine the two heads\n",
    "model = Model(inputs=base_model.input, outputs=[class_prediction, box_predictions])\n",
    "\n",
    "# For classification we will have sparse cateogirical crossentropy\n",
    "# For the bouding boxes we will have GIoU\n",
    "losses = { \n",
    "    \"class_output\": tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \"box_output\": my_GIoULoss\n",
    "    }\n",
    "\n",
    "# For the class labels we want to know the Accuracy\n",
    "# And for the bounding boxes we need to know GIoU\n",
    "metrics = {\n",
    "    'class_output': tf.keras.metrics.SparseCategoricalAccuracy(), \n",
    "    'box_output': my_GIoU\n",
    "    }\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses, metrics=metrics)\n",
    "\n",
    "stop = EarlyStopping(monitor = \"val_loss\", min_delta = 0.001, patience = 40, \n",
    "                    restore_best_weights = True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536a702",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b114be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3125/3125 - 3119s - loss: 2.5378 - class_output_loss: 2.0600 - box_output_loss: 0.4778 - class_output_sparse_categorical_accuracy: 0.5391 - box_output_my_GIoU: 0.5222 - val_loss: 2.0580 - val_class_output_loss: 1.5896 - val_box_output_loss: 0.4684 - val_class_output_sparse_categorical_accuracy: 0.6196 - val_box_output_my_GIoU: 0.5315 - 3119s/epoch - 998ms/step\n",
      "Epoch 2/5\n",
      "3125/3125 - 3154s - loss: 2.1095 - class_output_loss: 1.6470 - box_output_loss: 0.4624 - class_output_sparse_categorical_accuracy: 0.6034 - box_output_my_GIoU: 0.5376 - val_loss: 2.0220 - val_class_output_loss: 1.5619 - val_box_output_loss: 0.4601 - val_class_output_sparse_categorical_accuracy: 0.6247 - val_box_output_my_GIoU: 0.5399 - 3154s/epoch - 1s/step\n",
      "Epoch 3/5\n",
      "3125/3125 - 3086s - loss: 2.0078 - class_output_loss: 1.5518 - box_output_loss: 0.4560 - class_output_sparse_categorical_accuracy: 0.6198 - box_output_my_GIoU: 0.5440 - val_loss: 2.0096 - val_class_output_loss: 1.5535 - val_box_output_loss: 0.4561 - val_class_output_sparse_categorical_accuracy: 0.6321 - val_box_output_my_GIoU: 0.5438 - 3086s/epoch - 988ms/step\n",
      "Epoch 4/5\n",
      "3125/3125 - 3111s - loss: 1.9388 - class_output_loss: 1.4866 - box_output_loss: 0.4522 - class_output_sparse_categorical_accuracy: 0.6320 - box_output_my_GIoU: 0.5478 - val_loss: 2.0162 - val_class_output_loss: 1.5613 - val_box_output_loss: 0.4549 - val_class_output_sparse_categorical_accuracy: 0.6312 - val_box_output_my_GIoU: 0.5450 - 3111s/epoch - 995ms/step\n",
      "Epoch 5/5\n",
      "3125/3125 - 3273s - loss: 1.8819 - class_output_loss: 1.4329 - box_output_loss: 0.4491 - class_output_sparse_categorical_accuracy: 0.6423 - box_output_my_GIoU: 0.5509 - val_loss: 2.0304 - val_class_output_loss: 1.5776 - val_box_output_loss: 0.4528 - val_class_output_sparse_categorical_accuracy: 0.6291 - val_box_output_my_GIoU: 0.5471 - 3273s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(x=train_dataset, validation_data=val_dataset, epochs=5, callbacks=stop, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dcd0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "55e1d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input, output = load_element(validation_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18b0ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_cat = output['class_output'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e91a8819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0618831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, y_min, x_max, y_max = output['box_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e4e2f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = x_min.numpy()\n",
    "y_min = y_min.numpy()\n",
    "x_max = x_max.numpy()\n",
    "y_max = y_max.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c442be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bb = np.array([x_min, y_min, x_max, y_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "93564877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.109375, 0.      , 0.921875, 0.984375], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5a720aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_bb.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5a43633",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape\n",
    "m_input = tf.expand_dims(input, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0557942b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_cat, y_pred_bb = model.predict(m_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "09d4d3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([144], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8e54b07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.8616480e-08, 1.0000000e+00, 6.3599748e-09, 1.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c3c71121",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, iou, where = my_IoU_np(y_true_bb, y_pred_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ed944281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00214133], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fd9e3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, var1, var2, plot_name):\n",
    "    # Get the loss metrics from the trained model\n",
    "    c1 = history.history[var1]\n",
    "    c2 = history.history[var2]\n",
    "\n",
    "    epochs = range(len(c1))\n",
    "\n",
    "    # Plot the metrics\n",
    "    plt.plot(epochs, c1, 'b', label=var1)\n",
    "    plt.plot(epochs, c2, 'r', label=var2)\n",
    "    plt.title(str(plot_name))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ece5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
