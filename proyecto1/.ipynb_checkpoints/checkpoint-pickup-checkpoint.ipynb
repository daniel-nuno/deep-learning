{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6001f22e",
   "metadata": {},
   "source": [
    "Check-point file\n",
    "\n",
    "Load training and validation list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28daf417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuno\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.data import AUTOTUNE\n",
    "\n",
    "from tensorflow_addons.losses import GIoULoss\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('training_list.data', 'rb') as filehandle:\n",
    "    # Store the data as a binary data stream\n",
    "    training_list = pickle.load(filehandle)\n",
    "\n",
    "with open('validation_list.data', 'rb') as filehandle:\n",
    "    # Store the data as a binary data stream\n",
    "    validation_list = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f5875",
   "metadata": {},
   "source": [
    "Load dataset and error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34bd4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_element(element):\n",
    "    #make tensors list delimited by ,\n",
    "    element = tf.strings.split(element, sep=\",\")\n",
    "    #load image\n",
    "    img = tf.io.read_file(element[0])\n",
    "    #make sure is 3 channels\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    #conver to float [0,1)\n",
    "    #img = tf.image.convert_image_dtype(img, dtype=tf.float16)\n",
    "    #resize\n",
    "    img = tf.image.resize(img, (128, 128))\n",
    "    #category\n",
    "    #category = tf.constant(element[1])\n",
    "    category =tf.strings.to_number(element[1], tf.int32)\n",
    "    #bounding box\n",
    "    x_min = tf.strings.to_number(element[2])\n",
    "    y_min = tf.strings.to_number(element[3])\n",
    "    x_max = tf.strings.to_number(element[4])\n",
    "    y_max = tf.strings.to_number(element[5])\n",
    "    bb = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "    labels = {'class_output': category, 'box_output':bb}\n",
    "\n",
    "    return (img, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbad39a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_list)\n",
    "train_dataset = (train_dataset\n",
    "                 .shuffle(len(training_list))\n",
    "                 .map(load_element, num_parallel_calls=AUTOTUNE)\n",
    "                 .cache()\n",
    "                 .batch(bath_size)\n",
    "                 .prefetch(AUTOTUNE)\n",
    "                 )\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(validation_list)\n",
    "val_dataset = (val_dataset\n",
    "                 .shuffle(len(validation_list))\n",
    "                 .map(load_element, num_parallel_calls = AUTOTUNE)\n",
    "                 .cache()\n",
    "                 .batch(bath_size)\n",
    "                 .prefetch(AUTOTUNE)\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f12d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GIoU(bb_true, bb_pred):\n",
    "    #make zero as tensor\n",
    "    zero = tf.convert_to_tensor(0.0, bb_true.dtype)\n",
    "    #convert them to tensor clases\n",
    "    Ax1, Ay1, Ax2, Ay2 = tf.unstack(bb_true, 4, axis=-1)\n",
    "    Bx1, By1, Bx2, By2 = tf.unstack(bb_pred, 4, axis=-1)\n",
    "\n",
    "    #for the bounding box predicted make sure Bx2 > Bx1 y By2 > By1\n",
    "    bx1 = tf.math.minimum(Bx1, Bx2)\n",
    "    by1 = tf.math.minimum(By1, By2)\n",
    "    bx2 = tf.math.maximum(Bx1, Bx2)\n",
    "    by2 = tf.math.maximum(By1, By2)\n",
    "\n",
    "    #calculate area of true bounding box\n",
    "    A_area = (Ax2 - Ax1)*(Ay2 - Ay1)\n",
    "    #calculate area of predicted bounding box\n",
    "    B_area = (bx2 - bx1)*(by2 - by1)\n",
    "    \n",
    "    #calculate intersection over true and pred\n",
    "    #find the box overlaps both boxes\n",
    "    #each inter calculates the smallest stride\n",
    "    x_inter_1 = tf.math.maximum(bx1, Ax1)\n",
    "    y_inter_1 = tf.math.maximum(by1, Ay1)\n",
    "    x_inter_2 = tf.math.minimum(bx2, Ax2)\n",
    "    y_inter_2 = tf.math.minimum(by2, Ay2)\n",
    "    #get width\n",
    "    w_inter = tf.maximum(zero, x_inter_1 - x_inter_2)\n",
    "    #get height\n",
    "    h_inter = tf.maximum(zero, y_inter_1 - y_inter_2)\n",
    "    #intersection\n",
    "    I = w_inter * h_inter\n",
    "    #area over union\n",
    "    area_union = (B_area + A_area) - I\n",
    "    iou = tf.math.divide_no_nan(I, area_union)\n",
    "\n",
    "    #find the b box C smaller that surrounding/fits both A and B\n",
    "    Cx1 = tf.math.minimum(bx1, Ax1)\n",
    "    Cy1 = tf.math.minimum(by1, Ay1)\n",
    "    Cx2 = tf.math.maximum(bx2, Ax2)\n",
    "    Cy2 = tf.math.maximum(by2, Ay2)\n",
    "\n",
    "    #calculate the C area\n",
    "    C_area = (Cx2 - Cx1) * (Cy2 - Cy1)\n",
    "    #calculate giou\n",
    "    giou = iou - tf.math.divide_no_nan(C_area - area_union, C_area)\n",
    "    #calculate mean of all observations\n",
    "    m_giou = tf.reduce_mean(giou, axis=0)\n",
    "\n",
    "    return m_giou\n",
    "\n",
    "def my_GIoULoss(bb_true, bb_pred):\n",
    "    return 1.0 - my_GIoU(bb_true, bb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8c5ea",
   "metadata": {},
   "source": [
    "Load model and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc2b95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetV2M(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=Input(shape=(128,128,3)),\n",
    "    pooling=None,\n",
    "    include_preprocessing=True)\n",
    "\n",
    "base_model.trainable=False\n",
    "base_model_output = base_model.output\n",
    "\n",
    "no_of_classes = 200\n",
    "\n",
    "# We could also use Flatten()(x) but GAP is more effective, it reduces \n",
    "# Parameters and controls overfitting.\n",
    "flattened_output = GlobalAveragePooling2D()(base_model_output)\n",
    "#flattened_output = Flatten()(base_model_output)\n",
    "\n",
    "# Create our Classification Head, final layer contains \n",
    "# Ouput units = no. classes\n",
    "class_prediction = Dense(256, activation=\"relu\")(flattened_output)\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "#class_prediction = Dropout(0.2)(class_prediction)\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "class_prediction = Dropout(0.2)(class_prediction )\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "class_prediction = Dense(no_of_classes, activation='softmax',name=\"class_output\")(class_prediction)\n",
    "\n",
    "# Create Our Localization Head, final layer contains 4 nodes for x1,y1,x2,y2\n",
    "# Respectively.\n",
    "box_output = Dense(256, activation=\"relu\")(flattened_output)\n",
    "box_output = Dense(128, activation=\"relu\")(box_output)\n",
    "box_output = Dropout(0.2)(box_output)\n",
    "box_output = Dense(64, activation=\"relu\")(box_output)\n",
    "box_output = Dropout(0.2)(box_output)\n",
    "box_output = Dense(32, activation=\"relu\")(box_output)\n",
    "box_predictions = Dense(4, activation='sigmoid', name= \"box_output\")(box_output)\n",
    "\n",
    "# Now combine the two heads\n",
    "model = Model(inputs=base_model.input, outputs=[class_prediction, box_predictions])\n",
    "\n",
    "# For classification we will have cateogirical crossentropy\n",
    "# For the bouding boxes we will have mean squared error\n",
    "losses = { \n",
    "    \"class_output\": tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \"box_output\": my_GIoULoss\n",
    "    }\n",
    "\n",
    "# For the class labels we want to know the Accuracy\n",
    "# And for the bounding boxes we need to know the Mean squared error\n",
    "metrics = {\n",
    "    'class_output': tf.keras.metrics.SparseCategoricalAccuracy(), \n",
    "    'box_output': my_GIoU\n",
    "    }\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536a702",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b114be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 3704s 589ms/step - loss: 2.5242 - class_output_loss: 2.0459 - box_output_loss: 0.4783 - val_loss: 2.0962 - val_class_output_loss: 1.6232 - val_box_output_loss: 0.4731\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 3656s 585ms/step - loss: 2.1780 - class_output_loss: 1.7111 - box_output_loss: 0.4669 - val_loss: 2.0646 - val_class_output_loss: 1.5972 - val_box_output_loss: 0.4674\n",
      "Epoch 3/10\n",
      "1324/6250 [=====>........................] - ETA: 53:07:39 - loss: 2.0890 - class_output_loss: 1.6275 - box_output_loss: 0.4615"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=train_dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1b81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8abaf514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7e0e86f40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd0fcb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fdd810",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
