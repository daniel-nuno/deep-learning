{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/en/5/5f/Western_Institute_of_Technology_and_Higher_Education_logo.png)\n",
    "\n",
    "**InstitutoTecnológico y de Estudios Superiores de Occidente**\n",
    "\n",
    "**Maestría Ciencia de Datos**\n",
    "\n",
    "**Aprendizaje Profundo**\n",
    "\n",
    "# Proyecto: clasificación y localización de objetos #\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* * *\n",
    "\n",
    "Estudiante: Daniel Nuño <br>\n",
    "Profesor: Dr. Francisco Cervantes <br>\n",
    "Fecha entrega: Marzo 26, 2023 <br>\n",
    "\n",
    "* * *\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.data import AUTOTUNE\n",
    "\n",
    "#from tensorflow_addons.losses import GIoULoss\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_list.data', 'rb') as filehandle:\n",
    "    # Store the data as a binary data stream\n",
    "    training_list = pickle.load(filehandle)\n",
    "\n",
    "with open('validation_list.data', 'rb') as filehandle:\n",
    "    # Store the data as a binary data stream\n",
    "    validation_list = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_list.data', 'wb') as filehandle:\n",
    "    # Store the data as a binary data stream\n",
    "    pickle.dump(training_list, filehandle)\n",
    "\n",
    "with open('validation_list.data', 'wb') as filehandle:\n",
    "    # Store the data as a binary data stream\n",
    "    pickle.dump(validation_list, filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing data and functions\n",
    "\n",
    "Because the folder structure for training is different than validation and test, the pre processing is differently.\n",
    "\n",
    "### Pre processing training data\n",
    "\n",
    "Set paths for training and ids-categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path= \"C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/train\"\n",
    "\n",
    "project_id_path = \"C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/wnids.txt\"\n",
    "all_id_cat_path = \"C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/words.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read project ids as list. Make sure it has unique values. Make and index of integers from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_list = []\n",
    "with open(project_id_path) as f:\n",
    "    for line in f:\n",
    "        project_id_list.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure it has unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(project_id_list)) == len(project_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an index of integers from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_index_dict = {value: index for index, value in enumerate(project_id_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(project_index_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read file of categories as dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cat_dict = dict()\n",
    "with open(all_id_cat_path, 'r') as f:\n",
    "    for line in f:\n",
    "        resulting_line = line.strip().split('\\t')\n",
    "        id_cat_dict[resulting_line[0]] = resulting_line[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all list of files while separating bounding box files frome images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files_img = []\n",
    "training_files_bb = []\n",
    "for dirpath, dirnames, filenames in os.walk(img_path):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirpath, filename)\n",
    "        if path.endswith('txt'):\n",
    "            training_files_bb.append(path)\n",
    "        else:\n",
    "            training_files_img.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_files_bb), len(training_files_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_dict = dict()\n",
    "for file in training_files_bb:\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            img_name, xmin, ymin, xmax, ymax = line.strip().split('\\t')\n",
    "            bb_dict[img_name] = [xmin, ymin, xmax, ymax]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check elements of dictionary of bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(bb_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data set list that returns img full path, category, bounding box. Double back slash **'\\\\'** might needed to be updated depending on the users system.\n",
    "\n",
    "In tensorflow you can't have a tensor with more than one data type (tf.data.Dataset.from_tensor_slices function). Hence a workaround could be to create a tensor with data type tf.String and, on the occurrence (load_element function below), cast the field to the desired data type.\n",
    "\n",
    "> It is not possible to have a tf.Tensor with more than one data type. It is possible, however, to serialize arbitrary data structures as strings and store those in tf.Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = []\n",
    "for count, file in enumerate(training_files_img):\n",
    "    #get category and file name\n",
    "    _, category_key, _, image_name = training_files_img[count].split('\\\\')\n",
    "    #convert category to index from dictionary\n",
    "    category = project_index_dict[category_key]\n",
    "    #open image\n",
    "    img = cv.imread(file)\n",
    "    #get dimensions\n",
    "    h, w, _ = img.shape\n",
    "    #get correct size bounding box\n",
    "    original_bb = bb_dict[image_name]\n",
    "    rs_bb = [float(original_bb[0])/w,\n",
    "            float(original_bb[1])/h,\n",
    "            float(original_bb[2])/w,\n",
    "            float(original_bb[3])/h,\n",
    "            ]\n",
    "    # treat it as list\n",
    "    #example = (file, category, rs_bb)\n",
    "    #treat it as one string delimited by comas\n",
    "    example = \"\".join([file, ',',\n",
    "                        str(category), ',',\n",
    "                        str(rs_bb[0]), ',',\n",
    "                        str(rs_bb[1]), ',',\n",
    "                        str(rs_bb[2]), ',',\n",
    "                        str(rs_bb[3])])\n",
    "    #appended to final list\n",
    "    training_list.append(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the list to grab randomly in each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the lenght of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing validation data\n",
    "\n",
    "Path of images and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_val = \"C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/val/images\"\n",
    "val_annotations_txt = \"C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/val/val_annotations.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process annotations that contains category and bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_list = list()\n",
    "with open(val_annotations_txt, 'r') as f:\n",
    "    for line in f:\n",
    "        img_name, category_key, xmin, ymin, xmax, ymax = line.strip().split('\\t')\n",
    "        full_path = img_path_val + '/' + img_name\n",
    "        category = project_index_dict[category_key]\n",
    "        img = cv.imread(full_path)\n",
    "        h, w, _ = img.shape\n",
    "        rs_xmin = float(xmin)/w\n",
    "        rs_ymin = float(ymin)/h\n",
    "        rs_xmax = float(xmax)/w\n",
    "        rs_ymax = float(ymax)/h\n",
    "        rs_bb = [rs_xmin, rs_ymin, rs_xmax, rs_ymax]\n",
    "        #treat it as list\n",
    "        #example = (full_path, category, rs_bb)\n",
    "        #treat it as one string delimited by comas\n",
    "        example = \"\".join([full_path, ',',\n",
    "                        str(category), ',',\n",
    "                        str(rs_bb[0]), ',',\n",
    "                        str(rs_bb[1]), ',',\n",
    "                        str(rs_bb[2]), ',',\n",
    "                        str(rs_bb[3])])\n",
    "        validation_list.append(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check training and validation have the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/train\\\\n01917289\\\\images\\\\n01917289_323.JPEG,164,0.015625,0.078125,0.9375,0.8125'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/val/images/val_0.JPEG,163,0.0,0.5,0.6875,0.96875',\n",
       " 'C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/val/images/val_1.JPEG,1,0.8125,0.859375,0.890625,0.921875',\n",
       " 'C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/val/images/val_2.JPEG,132,0.0625,0.0,0.9375,0.859375']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_list[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load function and dataset\n",
    "\n",
    "Because we want to use TensorFlow in batches, it is important to use TensorFlow classes. TensorFlow Dataset allows to load data in small groups, instead of loading all into memory at once.\n",
    "\n",
    "> Supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
    "\n",
    "> - Create a source dataset from your input data.\n",
    "> - Apply dataset transformations to preprocess the data.\n",
    ">- Iterate over the dataset and process the elements.\n",
    "\n",
    "> Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.\n",
    "\n",
    "The following function load and treat the image element by element. To be used in the pre-fetched function. Each element is a string delimited by comas:\n",
    "- full image name, category, ,x min, y min, x max, y max.\n",
    "\n",
    "- category is an integer from indexing. To use Sparse Categorical Cross Entropy as loss. Expexted to save time in memory as well as computation because it simply uses a single integer for a class, rather than a whole vector. Activation function use softmax and neurons is num_classes. y_pred is [batch_size, num_classes].\n",
    "- bounding box is a list of 4 float numbers: x_min, y_min, x_max, y_max. Activation function use linear and neurons is 4. y_pred is [batch_size, 4].\n",
    "\n",
    "The function return a pair on input and targets (category and bounding box). This format is required for *model fit method*:\n",
    "\n",
    "> Args\n",
    "> x: Input data. It could be: ...A tf.data dataset. Should return a tuple of either (inputs, targets) or (inputs, targets, sample_weights)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_element(element):\n",
    "    #make tensors list delimited by ,\n",
    "    element = tf.strings.split(element, sep=\",\")\n",
    "    #load image\n",
    "    img = tf.io.read_file(element[0])\n",
    "    #make sure is 3 channels\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    #conver to float [0,1)\n",
    "    #img = tf.image.convert_image_dtype(img, dtype=tf.float16)\n",
    "    #resize\n",
    "    img = tf.image.resize(img, (128, 128))\n",
    "    #category\n",
    "    #category = tf.constant(element[1])\n",
    "    category =tf.strings.to_number(element[1], tf.int32)\n",
    "    #bounding box\n",
    "    x_min = tf.strings.to_number(element[2])\n",
    "    y_min = tf.strings.to_number(element[3])\n",
    "    x_max = tf.strings.to_number(element[4])\n",
    "    y_max = tf.strings.to_number(element[5])\n",
    "    #bb = [y_min, x_min, y_max, x_max]\n",
    "    bb = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "    labels = {'class_output': category, 'box_output':bb}\n",
    "\n",
    "    return (img, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, labels = load_element(training_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 128, 3), dtype=float32, numpy=\n",
       "array([[[ 36.    , 104.    ,  89.    ],\n",
       "        [ 32.5   , 101.25  ,  86.    ],\n",
       "        [ 25.5   ,  95.75  ,  80.    ],\n",
       "        ...,\n",
       "        [ 77.25  , 174.5   , 153.75  ],\n",
       "        [ 69.75  , 167.5   , 145.25  ],\n",
       "        [ 66.    , 164.    , 141.    ]],\n",
       "\n",
       "       [[ 28.75  ,  96.75  ,  81.75  ],\n",
       "        [ 25.875 ,  94.4375,  79.25  ],\n",
       "        [ 20.125 ,  89.8125,  74.25  ],\n",
       "        ...,\n",
       "        [ 77.3125, 173.9375, 152.375 ],\n",
       "        [ 70.4375, 167.3125, 144.625 ],\n",
       "        [ 67.    , 164.    , 140.75  ]],\n",
       "\n",
       "       [[ 14.25  ,  82.25  ,  67.25  ],\n",
       "        [ 12.625 ,  80.8125,  65.75  ],\n",
       "        [  9.375 ,  77.9375,  62.75  ],\n",
       "        ...,\n",
       "        [ 77.4375, 172.8125, 149.625 ],\n",
       "        [ 71.8125, 166.9375, 143.375 ],\n",
       "        [ 69.    , 164.    , 140.25  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 26.25  ,  85.25  ,  63.25  ],\n",
       "        [ 27.3125,  86.9375,  64.5625],\n",
       "        [ 29.4375,  90.3125,  67.1875],\n",
       "        ...,\n",
       "        [ 47.25  , 131.625 , 107.4375],\n",
       "        [ 51.75  , 136.875 , 112.3125],\n",
       "        [ 54.    , 139.5   , 114.75  ]],\n",
       "\n",
       "       [[ 38.75  ,  97.75  ,  75.75  ],\n",
       "        [ 37.4375,  96.8125,  74.1875],\n",
       "        [ 34.8125,  94.9375,  71.0625],\n",
       "        ...,\n",
       "        [ 36.25  , 120.375 ,  96.3125],\n",
       "        [ 38.75  , 123.125 ,  98.9375],\n",
       "        [ 40.    , 124.5   , 100.25  ]],\n",
       "\n",
       "       [[ 45.    , 104.    ,  82.    ],\n",
       "        [ 42.5   , 101.75  ,  79.    ],\n",
       "        [ 37.5   ,  97.25  ,  73.    ],\n",
       "        ...,\n",
       "        [ 30.75  , 114.75  ,  90.75  ],\n",
       "        [ 32.25  , 116.25  ,  92.25  ],\n",
       "        [ 33.    , 117.    ,  93.    ]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_output': <tf.Tensor: shape=(), dtype=int32, numpy=164>,\n",
       " 'box_output': [<tf.Tensor: shape=(), dtype=float32, numpy=0.015625>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=0.078125>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=0.9375>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=0.8125>]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following function **tf.data.Dataset** represents a potentially large set of elements. Iteration in training a streaming fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None),\n",
       " {'class_output': TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n",
       "  'box_output': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bath_size = 16\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_list)\n",
    "train_dataset = (train_dataset\n",
    "                 .shuffle(len(training_list))\n",
    "                 .map(load_element, num_parallel_calls=AUTOTUNE)\n",
    "                 .cache()\n",
    "                 .batch(bath_size)\n",
    "                 .prefetch(AUTOTUNE)\n",
    "                 )\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None),\n",
       " {'class_output': TensorSpec(shape=(None,), dtype=tf.int32, name=None),\n",
       "  'box_output': TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices(validation_list)\n",
    "val_dataset = (val_dataset\n",
    "                 .shuffle(len(validation_list))\n",
    "                 .map(load_element, num_parallel_calls = AUTOTUNE)\n",
    "                 .cache()\n",
    "                 .batch(bath_size)\n",
    "                 .prefetch(AUTOTUNE)\n",
    "                 )\n",
    "\n",
    "val_dataset.element_spec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define error (loss/metrics) function\n",
    "\n",
    "### Generalized intersection over union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GIoU(bb_true, bb_pred):\n",
    "    #make zero as tensor\n",
    "    zero = tf.convert_to_tensor(0.0, bb_true.dtype)\n",
    "    #convert them to tensor clases\n",
    "    Ax1, Ay1, Ax2, Ay2 = tf.unstack(bb_true, 4, axis=-1)\n",
    "    Bx1, By1, Bx2, By2 = tf.unstack(bb_pred, 4, axis=-1)\n",
    "\n",
    "    #for the bounding box predicted make sure Bx2 > Bx1 y By2 > By1\n",
    "    bx1 = tf.math.minimum(Bx1, Bx2)\n",
    "    by1 = tf.math.minimum(By1, By2)\n",
    "    bx2 = tf.math.maximum(Bx1, Bx2)\n",
    "    by2 = tf.math.maximum(By1, By2)\n",
    "\n",
    "    #calculate area of true bounding box\n",
    "    A_area = (Ax2 - Ax1)*(Ay2 - Ay1)\n",
    "    #calculate area of predicted bounding box\n",
    "    B_area = (bx2 - bx1)*(by2 - by1)\n",
    "    \n",
    "    #calculate intersection over true and pred\n",
    "    #find the box overlaps both boxes\n",
    "    #each inter calculates the smallest stride\n",
    "    x_inter_1 = tf.math.maximum(bx1, Ax1)\n",
    "    y_inter_1 = tf.math.maximum(by1, Ay1)\n",
    "    x_inter_2 = tf.math.minimum(bx2, Ax2)\n",
    "    y_inter_2 = tf.math.minimum(by2, Ay2)\n",
    "    #get width\n",
    "    w_inter = tf.maximum(zero, x_inter_1 - x_inter_2)\n",
    "    #get height\n",
    "    h_inter = tf.maximum(zero, y_inter_1 - y_inter_2)\n",
    "    #intersection\n",
    "    I = w_inter * h_inter\n",
    "    #area over union\n",
    "    area_union = (B_area + A_area) - I\n",
    "    iou = tf.math.divide_no_nan(I, area_union)\n",
    "\n",
    "    #find the b box C smaller that surrounding/fits both A and B\n",
    "    Cx1 = tf.math.minimum(bx1, Ax1)\n",
    "    Cy1 = tf.math.minimum(by1, Ay1)\n",
    "    Cx2 = tf.math.maximum(bx2, Ax2)\n",
    "    Cy2 = tf.math.maximum(by2, Ay2)\n",
    "\n",
    "    #calculate the C area\n",
    "    C_area = (Cx2 - Cx1) * (Cy2 - Cy1)\n",
    "    #calculate giou\n",
    "    giou = iou - tf.math.divide_no_nan(C_area - area_union, C_area)\n",
    "    #calculate mean of all observations\n",
    "    m_giou = tf.reduce_mean(giou, axis=0)\n",
    "\n",
    "    return m_giou\n",
    "\n",
    "def my_GIoULoss(bb_true, bb_pred):\n",
    "    return 1.0 - my_GIoU(bb_true, bb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom classification accuracy error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sparse_category_accurary(y_true, y_pred):\n",
    "    #y_true is expected to be integer\n",
    "    #y_pred is a numpy.ndarray with the normalized probabilities\n",
    "    acc = np.dot(1, np.not_equal(y_true, np.argmax(y_pred, axis=1)))\n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom bounding box IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_IoU_np(y_true, y_pred):\n",
    "    #becausse model predict returns a numpy.ndarray the convert to tensors because le function already works a tensors\n",
    "    bb_true = tf.convert_to_tensor(y_true, y_true.dtype)\n",
    "    bb_pred = tf.convert_to_tensor(y_pred, y_pred.dtype)\n",
    "\n",
    "    #make zero as tensor\n",
    "    zero = tf.convert_to_tensor(0.0, bb_true.dtype)\n",
    "    #convert them to tensor clases\n",
    "    Ax1, Ay1, Ax2, Ay2 = tf.unstack(bb_true, 4, axis=-1)\n",
    "    Bx1, By1, Bx2, By2 = tf.unstack(bb_pred, 4, axis=-1)\n",
    "\n",
    "    #for the bounding box predicted make sure Bx2 > Bx1 y By2 > By1\n",
    "    bx1 = tf.math.minimum(Bx1, Bx2)\n",
    "    by1 = tf.math.minimum(By1, By2)\n",
    "    bx2 = tf.math.maximum(Bx1, Bx2)\n",
    "    by2 = tf.math.maximum(By1, By2)\n",
    "\n",
    "    #calculate area of true bounding box\n",
    "    A_area = (Ax2 - Ax1)*(Ay2 - Ay1)\n",
    "    #calculate area of predicted bounding box\n",
    "    B_area = (bx2 - bx1)*(by2 - by1)\n",
    "    \n",
    "    #calculate intersection over true and pred\n",
    "    #find the box overlaps both boxes\n",
    "    #each inter calculates the smallest stride\n",
    "    x_inter_1 = tf.math.maximum(bx1, Ax1)\n",
    "    y_inter_1 = tf.math.maximum(by1, Ay1)\n",
    "    x_inter_2 = tf.math.minimum(bx2, Ax2)\n",
    "    y_inter_2 = tf.math.minimum(by2, Ay2)\n",
    "    #get width\n",
    "    w_inter = tf.maximum(zero, x_inter_1 - x_inter_2)\n",
    "    #get height\n",
    "    h_inter = tf.maximum(zero, y_inter_1 - y_inter_2)\n",
    "    #intersection\n",
    "    I = w_inter * h_inter\n",
    "    #area over union\n",
    "    area_union = (B_area + A_area) - I\n",
    "    iou = tf.math.divide_no_nan(I, area_union)\n",
    "\n",
    "    #convert back to numpy\n",
    "    iou = iou.numpy()\n",
    "    #check if is over 50% then 0 otherwise 1\n",
    "    over_50 = np.where(iou>0.5, 0, 1)\n",
    "\n",
    "    return over_50"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine both to return a correct match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_error(y_true, y_pred):\n",
    "    d = my_sparse_category_accurary(y_true, y_pred)\n",
    "    f = my_IoU_np(y_true, y_pred)\n",
    "    e = np.max(d, f)\n",
    "    return e.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Models that are pre trained already did the heavy lifting on getting a tested architecture and fine tuned parameters. Premade architectures with pre-trained weights.\n",
    "\n",
    "For EfficientNetV2, by default input preprocessing is included as a part of the model (as a Rescaling layer), and thus tf.keras.applications.efficientnet_v2.preprocess_input is actually a pass-through function. In this use case, EfficientNetV2 models expect their inputs to be float tensors of pixels with values in the [0-255] range. At the same time, preprocessing as a part of the model (i.e. Rescaling layer) can be disabled by setting include_preprocessing argument to False. With preprocessing disabled EfficientNetV2 models expect their inputs to be float tensors of pixels with values in the [-1, 1] range.\n",
    "\n",
    "### Load architecture\n",
    "\n",
    "We’ll first download the model but exclude the top since we’ll be adding our own custom top and resize the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetV2M(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=Input(shape=(128,128,3)),\n",
    "    input_shape=(128,128,3),\n",
    "    pooling=None,\n",
    "    include_preprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIoU loss from tensorflow addons\n",
    "\n",
    "GIoU loss from tensorflow addons is a function that requires following arguments. \n",
    "\n",
    "- true: true targets tensor. The coordinates of the each bounding box in boxes are encoded as [y_min, x_min, y_max, x_max].\n",
    "- pred: predictions tensor. The coordinates of the each bounding box in boxes are encoded as [y_min, x_min, y_max, x_max].\n",
    "- de: one of ['giou', 'iou'], decided to calculate GIoU or IoU loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define rest of the multi-output mode for the two tasks\n",
    "\n",
    "We won’t be training from scratch so we will use transfer learning and split output in two.\n",
    "\n",
    "- class_output\n",
    "- box_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=False\n",
    "base_model_output = base_model.output\n",
    "\n",
    "no_of_classes = 200\n",
    "\n",
    "# We could also use Flatten()(x) but GAP is more effective, it reduces \n",
    "# Parameters and controls overfitting.\n",
    "#flattened_output = GlobalAveragePooling2D()(base_model_output)\n",
    "flattened_output = Flatten()(base_model_output)\n",
    "\n",
    "# Create our Classification Head, final layer contains \n",
    "# Ouput units = no. classes\n",
    "class_prediction = Dense(256, activation=\"relu\")(flattened_output)\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "#class_prediction = Dropout(0.2)(class_prediction)\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "class_prediction = Dropout(0.2)(class_prediction )\n",
    "#class_prediction = Dense(256, activation=\"relu\")(class_prediction)\n",
    "class_prediction = Dense(no_of_classes, activation='softmax',name=\"class_output\")(class_prediction)\n",
    "\n",
    "# Create Our Localization Head, final layer contains 4 nodes for x1,y1,x2,y2\n",
    "# Respectively.\n",
    "box_output = Dense(256, activation=\"relu\")(flattened_output)\n",
    "box_output = Dense(128, activation=\"relu\")(box_output)\n",
    "box_output = Dropout(0.2)(box_output)\n",
    "box_output = Dense(64, activation=\"relu\")(box_output)\n",
    "box_output = Dropout(0.2)(box_output)\n",
    "box_output = Dense(32, activation=\"relu\")(box_output)\n",
    "box_predictions = Dense(4, activation='linear', name= \"box_output\")(box_output)\n",
    "\n",
    "# Now combine the two heads\n",
    "model = Model(inputs=base_model.input, outputs=[class_prediction, box_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 200) dtype=float32 (created by layer 'class_output')>,\n",
       " <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'box_output')>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification we will have cateogirical crossentropy\n",
    "# For the bouding boxes we will have mean squared error\n",
    "losses = { \n",
    "    \"class_output\": tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    \"box_output\": GIoULoss()\n",
    "    }\n",
    "\n",
    "# For the class labels we want to know the Accuracy\n",
    "# And for the bounding boxes we need to know the Mean squared error\n",
    "metrics = {\n",
    "    'class_output': tf.keras.metrics.SparseCategoricalAccuracy(), \n",
    "    'box_output': 'mse'\n",
    "    }\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 4609s 734ms/step - loss: 4.2470 - class_output_loss: 3.2470 - box_output_loss: 1.0001 - class_output_accuracy: 0.3141 - box_output_mse: 19471.8203 - val_loss: 25.7491 - val_class_output_loss: 24.7491 - val_box_output_loss: 1.0000 - val_class_output_accuracy: 0.0050 - val_box_output_mse: 49752.5508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e8df7b9670>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_dataset, validation_data=val_dataset , epochs=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data\n",
    "\n",
    "### Pipeline for test and new data\n",
    "\n",
    "1. define folder path for images\n",
    "2. get images names\n",
    "3. recursively:\n",
    "    - load image\n",
    "    - resize\n",
    "    - get category and bounding box from nn\n",
    "    - save results to a list containing the image name, category and bounding box\n",
    "4. save list of results to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
