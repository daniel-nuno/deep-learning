{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/en/5/5f/Western_Institute_of_Technology_and_Higher_Education_logo.png)\n",
    "\n",
    "**InstitutoTecnológico y de Estudios Superiores de Occidente**\n",
    "\n",
    "**Maestría Ciencia de Datos**\n",
    "\n",
    "**Aprendizaje Profundo**\n",
    "\n",
    "# Proyecto: clasificación y localización de objetos #\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* * *\n",
    "\n",
    "Estudiante: Daniel Nuño <br>\n",
    "Profesor: Dr. Francisco Cervantes <br>\n",
    "Fecha entrega: Marzo 26, 2023 <br>\n",
    "\n",
    "* * *\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.data import AUTOTUNE\n",
    "\n",
    "#from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input\n",
    "#from tensorflow.keras.applications import VGG16\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training processing data\n",
    "\n",
    "Set paths for training and ids-categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path= \"C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/train\"\n",
    "\n",
    "project_id_path = \"C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/wnids.txt\"\n",
    "all_id_cat_path = \"C:/Users/nuno/Desktop/deep-learning-data/proyecto1/tiny-imagenet-200/words.txt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read project ids as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_list = []\n",
    "with open(project_id_path) as f:\n",
    "    for line in f:\n",
    "        project_id_list.append(line.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read categories as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cat_dict = dict()\n",
    "with open(all_id_cat_path, 'r') as f:\n",
    "    for line in f:\n",
    "        resulting_line = line.strip().split('\\t')\n",
    "        id_cat_dict[resulting_line[0]] = resulting_line[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all list of files. Separate bounding box files frome images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_files_img = []\n",
    "training_files_bb = []\n",
    "for dirpath, dirnames, filenames in os.walk(img_path):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirpath, filename)\n",
    "        if path.endswith('txt'):\n",
    "            training_files_bb.append(path)\n",
    "        else:\n",
    "            training_files_img.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 100000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_files_bb), len(training_files_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_dict = dict()\n",
    "for file in training_files_bb:\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            img_name, xmin, ymin, xmax, ymax = line.strip().split('\\t')\n",
    "            bb_dict[img_name] = [xmin, ymin, xmax, ymax]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check elements of dictionary of bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bb_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data set list that returns img full path, category, bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_list = []\n",
    "for file in training_files_img:\n",
    "    #get category and file name\n",
    "    _, category, _, image_name = training_files_img[0].split('\\\\')\n",
    "    #open image\n",
    "    img = cv.imread(file)\n",
    "    #get dimensions\n",
    "    h, w, _ = img.shape\n",
    "    #get correct size bounding box\n",
    "    original_bb = bb_dict[image_name]\n",
    "    sized_bb = [float(original_bb[0])/w,\n",
    "               float(original_bb[1])/h,\n",
    "               float(original_bb[2])/w,\n",
    "               float(original_bb[3])/h,\n",
    "                ]\n",
    "    # treat it as list\n",
    "    example = [file, category, sized_bb]\n",
    "    #appended to final list\n",
    "    training_list.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
