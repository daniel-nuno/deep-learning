{"cells":[{"cell_type":"markdown","metadata":{"id":"7Zs4Y06MzIbb"},"source":["#Actividad 6. Ejemplo de solución\n","\n","### Etapa 1\n","\n","*Implementa un generador para los conjuntos de datos de entrenamiento, validación y prueba. En caso de ser necesario, aplica el aumento de datos para generar más imágenes.\n","Antes de iniciar la implementación determina ¿cuál debería ser la forma de los datos de entrada y salida esperada para tu modelo?*\n","\n"]},{"cell_type":"markdown","metadata":{"id":"QHBtjiNZ0ZgQ"},"source":["Para este ejemplo de solución, implementaremos un **generador de datos que reciba como entrada una lista de cadenas de texto** con la siguiente información:\n","\n","**\"images_path/image_name.jpg,x_min,y_min,x_max,y_max\"**\n","\n","Inicialmente el archivo **airplanes.csv** contiene las anotaciones en el siguiente formato.\n","\n","**\"image_name.jpg,x_min,y_min,x_max,y_max\"**\n","\n","Por lo que sería necesario agregar a cada anotación la ruta en donde se encuentran las imágenes.\n","\n","Opcionalmente, para reducir el trabajo del generador de datos durante la etapa de entrenamiento, podemos escalar el *boundingbox (x_min, y_min, x_max, y_max)* de cada imagen acorde a sus dimensiones: (height, width, 3). Esto es:\n","\n","*  x_min = x_min/width \n","*  y_min = y_min/height\n","*  x_max = x_max/width\n","*  x_min = x_min/height\n","\n","Para implementar la escala, necesitariamos abrir cada imagen para consultar los valores de: width y height.\n","\n","Nota: considere el manejo de los tipos de datos.\n","\n","La **salida del generador** un **dataset**, en donde cada elemento es una dupla: (x, y). Tal que\n","\n","*  x:  imágen de dimensiones (h, w, 3)\n","*  y:  boundingbox (x_min, y_min, x_max, y_max) "]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":273,"status":"ok","timestamp":1678159812260,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"g9YeZ1Wx878R"},"outputs":[],"source":["import cv2 as cv\n","import random\n","import tensorflow as tf\n","from tensorflow.data import AUTOTUNE"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1678157321780,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"ywOPbXT-yXBM"},"outputs":[{"ename":"SyntaxError","evalue":"(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2550021102.py, line 1)","output_type":"error","traceback":["\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    img_path= \"C:\\Users\\nuno\\Desktop\\deep-learning-data\\activity6\\dataset\\images\"\u001b[0m\n\u001b[1;37m                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"]}],"source":["img_path= \"C:\\Users\\nuno\\Desktop\\deep-learning-data\\activity6\\dataset\\images\"\n","annotations_path = \"C:\\Users\\nuno\\Desktop\\deep-learning-data\\activity6\\dataset\\airplanes.csv\""]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678157424955,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"inb4BQCJ8Hh7"},"outputs":[],"source":["def preprocess_annotation(img_src, annotation):\n","  filename, x_min, y_min, x_max, y_max = annotation.split(\",\")\n","  img_path = img_src + \"/\" + filename\n","  img = cv.imread(img_path)\n","  h, w, _ = img.shape\n","  annotation = \"\".join([img_path, \",\", str(float(x_min)/w), \",\",\n","                        str(float(y_min)/h), \",\",\n","                        str(float(x_max)/w), \",\",\n","                        str(float(y_max)/h)])\n","  return annotation"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1678157426463,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"RceZ0zV4979N","outputId":"10618e9b-347f-44f6-d458-48f459fc9592"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/DL2023p-licd/S06/Actividad 6/data/images/image_0002.jpg,0.14713216957605985,0.19021739130434784,0.8528678304239401,0.8315217391304348\n"]}],"source":["txt = preprocess_annotation(img_path, \"image_0002.jpg,59,35,342,153\")\n","print(txt)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1678158056873,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"tWq6ONL1-zBs"},"outputs":[],"source":["def build_datasets(images_path, annotation_path, train_split=0.95, val_split=0.1):\n","  \n","  annotations = open(annotation_path).read().splitlines()\n","  examples = [ preprocess_annotation(images_path, item) for item in annotations ]\n","  \n","  random.shuffle(examples)\n","\n","  #Aplicar el split al conjunto de datos\n","  s = int(len(examples)*train_split)\n","  train_examples = examples[:s]\n","  test_examples = examples[s:]\n","\n","  s = int(len(train_examples)*val_split)\n","  val_examples = train_examples[:s]\n","  train_examples = train_examples[s:]\n","\n","  return train_examples, val_examples, test_examples"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":471171,"status":"ok","timestamp":1678158804982,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"n9nj_FNqBvp4"},"outputs":[],"source":["train_data, val_data, test_data = build_datasets(img_path, annotations_path, 0.95, 0.1)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1678158830616,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"gsakaMCaCG5u","outputId":"ac6082ec-7d2b-4bbe-b762-b3e516f43c4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/DL2023p-licd/S06/Actividad 6/data/images/image_0485.jpg,0.14285714285714285,0.16560509554140126,0.8771929824561403,0.8280254777070064\n"]}],"source":["print(train_data[0])"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1678159532770,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"W5B7tpv3GjBw","outputId":"0a5038b2-ed3e-4d66-e401-28dc870edbdb"},"outputs":[{"name":"stdout","output_type":"stream","text":["76\n"]}],"source":["print(len(val_data))"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":288,"status":"ok","timestamp":1678159360195,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"0dCG3kSkC79t"},"outputs":[],"source":["def loadExample(example):\n","  # Extraer de la cadena image, bbox \n","  str_tensors = tf.strings.split(example, sep=\",\")\n","\n","  # Cargar la imagen\n","  img = tf.io.read_file(str_tensors[0])\n","  img = tf.image.decode_jpeg(img, channels=3)\n","  img = tf.image.convert_image_dtype(img, dtype=tf.float16)\n","  img = tf.image.resize(img, (128, 128))\n","\n","  x_min = tf.strings.to_number(str_tensors[1])\n","  y_min = tf.strings.to_number(str_tensors[2])\n","  x_max = tf.strings.to_number(str_tensors[3])\n","  y_max = tf.strings.to_number(str_tensors[4])\n","\n","  bbox = [x_min, y_min, x_max, y_max]\n","          \n","  return img, bbox"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1678159361295,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"zq651SfnFtHV"},"outputs":[],"source":["img, bbox = loadExample(train_data[0])"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1678159371118,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"6txrPhH1F8ec","outputId":"266b463e-6c9d-471f-cfbb-8d9bf8c41dd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[<tf.Tensor: shape=(), dtype=float32, numpy=0.14285715>, <tf.Tensor: shape=(), dtype=float32, numpy=0.1656051>, <tf.Tensor: shape=(), dtype=float32, numpy=0.877193>, <tf.Tensor: shape=(), dtype=float32, numpy=0.82802546>]\n"]}],"source":["print(bbox)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":934,"status":"ok","timestamp":1678159902023,"user":{"displayName":"Francisco Cervantes","userId":"05495956095332044751"},"user_tz":360},"id":"0tMX3ygoGUfS"},"outputs":[],"source":["# Pipelines \n","\n","batch_size = 32\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n","train_dataset = (train_dataset\n","                 .shuffle(len(train_data))\n","                 .map(loadExample, num_parallel_calls=AUTOTUNE)\n","                 .cache()\n","                 .batch(batch_size)\n","                 .prefetch(AUTOTUNE)\n","                 )\n","\n","val_dataset = tf.data.Dataset.from_tensor_slices(val_data)\n","val_dataset = (val_dataset\n","                 .shuffle(len(val_data))\n","                 .map(loadExample, num_parallel_calls=AUTOTUNE)\n","                 .cache()\n","                 .batch(batch_size)\n","                 .prefetch(AUTOTUNE)\n","                 )"]},{"cell_type":"markdown","metadata":{"id":"KKWdZWRwzhPe"},"source":["### Etapa 2\n","Para la arquitectura de tu modelo, se sugiere que elijas como base uno de los modelos preentrenados de tensorflow.keras.applications, por ejemplo: resnet, xception o vgg."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOx4J8Wyz005"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"F43WzIcWzkTx"},"source":["\n","\n","### Etapa 3\n","\n","En caso de ser necesario, agrega capas de entrada, capas ocultas y de salida para que tu modelo realiza de forma apropiada la tarea de localización. Para determinar la configuración de la capa de salida, recuerda cuál es la salida esperada para tu modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RwuR9RQ_z1Sd"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_42RptSUzv9d"},"source":["### Etapa 4\n","\n","Entrena y valida tu modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wInSpfHAz10C"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"naWagjW4zxn1"},"source":["### Etapa 5\n","\n","Evalua tu modelo utilizando las imágenes de tu conjunto de pruebas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3QGWoAEzu1Q"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNWAoIuP+BTULCN9RUVbBvk","collapsed_sections":["F43WzIcWzkTx"],"mount_file_id":"1ZTv9Y70-nN9llTzpYjIJLWxR0eLa5b82","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
