{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/en/5/5f/Western_Institute_of_Technology_and_Higher_Education_logo.png)\n",
    "\n",
    "**InstitutoTecnológico y de Estudios Superiores de Occidente**\n",
    "\n",
    "**Maestría Ciencia de Datos**\n",
    "\n",
    "**Aprendizaje Profundo**\n",
    "\n",
    "# Actividad 6 Construcción de un modelo para localizar aviones #\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* * *\n",
    "\n",
    "Estudiante: Daniel Nuño <br>\n",
    "Profesor: Dr. Francisco Cervantes <br>\n",
    "Fecha entrega: Marzo 12, 2023 <br>\n",
    "\n",
    "* * *\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Implemente un generador para los conjuntos de datos\n",
    "\n",
    "Entrenamiento, validación y prueba. En caso de ser necesario, aplica el aumento de datos para generar más imágenes. (20 pts)\n",
    "Antes de iniciar la implementación determina ¿cuál debería ser la forma de los datos de entrada y salida esperada para tu modelo?\n",
    "\n",
    "\n",
    "> Para este ejemplo de solución, implementaremos un **generador de datos que reciba como entrada una lista de cadenas de texto** con la siguiente información:\n",
    ">\n",
    "> **\"images_path/image_name.jpg,x_min,y_min,x_max,y_max\"**\n",
    ">\n",
    "> Inicialmente el archivo **airplanes.csv** contiene las anotaciones en el siguiente formato.\n",
    ">\n",
    "> **\"image_name.jpg,x_min,y_min,x_max,y_max\"**\n",
    ">\n",
    "> Por lo que sería necesario agregar a cada anotación la ruta en donde se encuentran las imágenes.\n",
    ">\n",
    "> Opcionalmente, para reducir el trabajo del generador de datos durante la etapa de entrenamiento, podemos escalar el *boundingbox (x_min, y_min, x_max, y_max)* de cada imagen acorde a sus dimensiones: (height, width, 3). Esto es:\n",
    ">\n",
    "> *  x_min = x_min/width \n",
    "> *  y_min = y_min/height\n",
    "> *  x_max = x_max/width\n",
    "> *  x_min = x_min/height\n",
    ">\n",
    "> Para implementar la escala, necesitariamos abrir cada imagen para consultar los valores de: width y height.\n",
    ">\n",
    "> Nota: considere el manejo de los tipos de datos.\n",
    ">\n",
    "> La **salida del generador** un **dataset**, en donde cada elemento es una dupla: (x, y). Tal que\n",
    ">\n",
    "> *  x:  imágen de dimensiones (h, w, 3)\n",
    "> *  y:  boundingbox (x_min, y_min, x_max, y_max) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path= \"C:/Users/nuno/Desktop/deep-learning-data/activity6/dataset/images\"\n",
    "annotations_path = \"C:/Users/nuno/Desktop/deep-learning-data/activity6/dataset/airplanes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_annotation(img_src, annotation):\n",
    "  filename, x_min, y_min, x_max, y_max = annotation.split(\",\")\n",
    "  img_path = img_src + \"/\" + filename\n",
    "  img = cv.imread(img_path)\n",
    "  h, w, _ = img.shape\n",
    "  annotation = \"\".join([img_path, \",\", str(float(x_min)/w), \",\",\n",
    "                        str(float(y_min)/h), \",\",\n",
    "                        str(float(x_max)/w), \",\",\n",
    "                        str(float(y_max)/h)])\n",
    "  return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/nuno/Desktop/deep-learning-data/activity6/dataset/images/image_0002.jpg,0.14713216957605985,0.19021739130434784,0.8528678304239401,0.8315217391304348\n"
     ]
    }
   ],
   "source": [
    "txt = preprocess_annotation(img_path, \"image_0002.jpg,59,35,342,153\")\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_datasets(images_path, annotation_path, train_split=0.95, val_split=0.1):\n",
    "  \n",
    "  annotations = open(annotation_path).read().splitlines()\n",
    "  examples = [ preprocess_annotation(images_path, item) for item in annotations ]\n",
    "  \n",
    "  random.shuffle(examples)\n",
    "\n",
    "  #Aplicar el split al conjunto de datos\n",
    "  s = int(len(examples)*train_split)\n",
    "  train_examples = examples[:s]\n",
    "  test_examples = examples[s:]\n",
    "\n",
    "  s = int(len(train_examples)*val_split)\n",
    "  val_examples = train_examples[:s]\n",
    "  train_examples = train_examples[s:]\n",
    "\n",
    "  return train_examples, val_examples, test_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = build_datasets(img_path, annotations_path, 0.95, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/nuno/Desktop/deep-learning-data/activity6/dataset/images/image_0116.jpg,0.1319796954314721,0.18235294117647058,0.8527918781725888,0.8176470588235294\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadExample(example):\n",
    "  # Extraer de la cadena image, bbox \n",
    "  str_tensors = tf.strings.split(example, sep=\",\")\n",
    "\n",
    "  # Cargar la imagen\n",
    "  img = tf.io.read_file(str_tensors[0])\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, dtype=tf.float16)\n",
    "  img = tf.image.resize(img, (128, 128))\n",
    "\n",
    "  x_min = tf.strings.to_number(str_tensors[1])\n",
    "  y_min = tf.strings.to_number(str_tensors[2])\n",
    "  x_max = tf.strings.to_number(str_tensors[3])\n",
    "  y_max = tf.strings.to_number(str_tensors[4])\n",
    "\n",
    "  bbox = [x_min, y_min, x_max, y_max]\n",
    "          \n",
    "  return img, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=0.13197969>, <tf.Tensor: shape=(), dtype=float32, numpy=0.18235295>, <tf.Tensor: shape=(), dtype=float32, numpy=0.8527919>, <tf.Tensor: shape=(), dtype=float32, numpy=0.81764704>]\n"
     ]
    }
   ],
   "source": [
    "img, bbox = loadExample(train_data[0])\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines \n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "train_dataset = (train_dataset\n",
    "                 .shuffle(len(train_data))\n",
    "                 .map(loadExample, num_parallel_calls=AUTOTUNE)\n",
    "                 .cache()\n",
    "                 .batch(batch_size)\n",
    "                 .prefetch(AUTOTUNE)\n",
    "                 )\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_data)\n",
    "val_dataset = (val_dataset\n",
    "                 .shuffle(len(val_data))\n",
    "                 .map(loadExample, num_parallel_calls=AUTOTUNE)\n",
    "                 .cache()\n",
    "                 .batch(batch_size)\n",
    "                 .prefetch(AUTOTUNE)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Elección como base uno de los modelos preentrenados\n",
    "\n",
    "Para la arquitectura de tu modelo, se sugiere que elijas como base uno de los modelos preentrenados de [tensorflow.keras.applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications), por ejemplo: resnet, xception, vgg, etc.\n",
    "\n",
    "\n",
    "Intentare primero con **Resnet** para ser una buena selección como modelo preentrenado por que el paper meciona una mejora relative 28% con el conjunto COCO para detección de objetos.\n",
    "\n",
    "\n",
    "> ... we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Agrega capas de entrada, capas ocultas y de salida\n",
    "\n",
    "En caso de ser necesario, agrega capas de entrada, capas ocultas y de salida para que tu modelo realiza de forma apropiada la tarea de localización. Para determinar la configuración de la capa de salida, recuerda cuál es la salida esperada para tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import resnet\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "\n",
    "model_resnet = resnet.ResNet101(weights=\"imagenet\", include_top=False, input_shape=(128,128,3))\n",
    "\n",
    "model_resnet.trainable = False            # No queremos continuar entrenando los pesos de VGG16\n",
    "output_resnet = model_resnet.output        # Hacemos referencia al tensor de salida de VGG16\n",
    "\n",
    "# Ahora agreguemos algunas capas y concluyamos con las regresión\n",
    "\n",
    "# Regresión (4 valores reales)\n",
    "x_tensor = Flatten()(output_resnet)\n",
    "x_tensor = Dense(25, activation=\"relu\")(x_tensor)\n",
    "output_tensor = Dense(4, activation=\"relu\", name = \"output\")(x_tensor)\n",
    "\n",
    "my_moedl = Model(inputs=input_tensor, outputs=output_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = resnet.ResNet101(\n",
    "                            weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "                            input_shape=(128, 128, 3),\n",
    "                            include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = Input(shape=(128, 128, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x =  Flatten()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = Dense(4, activation=\"relu\", name = \"output\")(x)\n",
    "my_model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_weights: 2\n",
      "non_trainable_weights: 624\n"
     ]
    }
   ],
   "source": [
    "print(\"trainable_weights:\", len(my_model.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(my_model.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " resnet101 (Functional)      (None, 4, 4, 2048)        42658176  \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 4)                 131076    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,789,252\n",
      "Trainable params: 131,076\n",
      "Non-trainable params: 42,658,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Entrena y valida tu modelo. \n",
    "\n",
    "- Utilizando como función de pérdida el error cuadrado medio y accuracy como métrica.\n",
    "- Utilizando como métrica: IoU.\n",
    "- Utilizando como función de pérdida y métrica: GIoU.\n",
    "\n",
    "### Utilizando como función de pérdida el error cuadrado medio y accuracy como métrica. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "22/22 [==============================] - 33s 1s/step - loss: 0.0572 - accuracy: 0.5000 - val_loss: 0.0269 - val_accuracy: 0.9868\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - 23s 1s/step - loss: 0.0192 - accuracy: 0.6813 - val_loss: 0.0187 - val_accuracy: 0.9342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f462b94640>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=['mse'],\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "my_model.fit(train_dataset, epochs=2, validation_data=val_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando como métrica: IoU.\n",
    "\n",
    "Existe una librería llamada tensorflow_addons que tiene diferentes metricos, perdidas y optimizadores; incluido IoU. Pero la version de python tiene que ser menor a 3.10.\n",
    "\n",
    "Entonces se tiene que implemetar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    \n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "def IoU_Own(y_true, y_pred):\n",
    "    \n",
    "    # Note: the type float32 is very important. It must be the same type as the output from\n",
    "    # the python function above or you too may spend many late night hours \n",
    "    # trying to debug and almost give up.\n",
    "\n",
    "    iou = tf.py_function(bb_intersection_over_union, [y_true, y_pred], tf.float32)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    \n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = tf.maximum(boxA[0], boxB[0])\n",
    "    yA = tf.maximum(boxA[1], boxB[1])\n",
    "    xB = tf.minimum(boxA[2], boxB[2])\n",
    "    yB = tf.minimum(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = tf.maximum(0, xB - xA + 1) * tf.maximum(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / tf.float32(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "def IoU_Own(y_true, y_pred):\n",
    "    \n",
    "    # Note: the type float32 is very important. It must be the same type as the output from\n",
    "    # the python function above or you too may spend many late night hours \n",
    "    # trying to debug and almost give up.\n",
    "\n",
    "    iou = tf.py_function(bb_intersection_over_union, [y_true, y_pred], tf.float32)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'EagerPyFunc' defined at (most recent call last):\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\nuno\\AppData\\Local\\Temp\\ipykernel_6484\\3160373843.py\", line 5, in <cell line: 5>\n      my_model.fit(train_dataset, epochs=2, validation_data=val_dataset)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 894, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 987, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 501, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 646, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\nuno\\AppData\\Local\\Temp\\ipykernel_6484\\3427449114.py\", line 27, in IoU_Own\n      iou = tf.py_function(bb_intersection_over_union, [y_true, y_pred], tf.float32)\nNode: 'EagerPyFunc'\nTypeError: 'DType' object is not callable\nTraceback (most recent call last):\n\n  File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\nuno\\AppData\\Local\\Temp\\ipykernel_6484\\3507677061.py\", line 17, in bb_intersection_over_union\n    iou = interArea / tf.float32(boxAArea + boxBArea - interArea)\n\nTypeError: 'DType' object is not callable\n\n\n\t [[{{node EagerPyFunc}}]] [Op:__inference_train_function_118534]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nuno\\Desktop\\daniel-nuno\\deep-learning\\activity6\\activity6.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nuno/Desktop/daniel-nuno/deep-learning/activity6/activity6.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m my_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nuno/Desktop/daniel-nuno/deep-learning/activity6/activity6.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nuno/Desktop/daniel-nuno/deep-learning/activity6/activity6.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m               metrics\u001b[39m=\u001b[39mIoU_Own)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nuno/Desktop/daniel-nuno/deep-learning/activity6/activity6.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m my_model\u001b[39m.\u001b[39;49mfit(train_dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_dataset)\n",
      "File \u001b[1;32mc:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'EagerPyFunc' defined at (most recent call last):\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n      self._run_once()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n      handle._run()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\nuno\\AppData\\Local\\Temp\\ipykernel_6484\\3160373843.py\", line 5, in <cell line: 5>\n      my_model.fit(train_dataset, epochs=2, validation_data=val_dataset)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 894, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 987, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 501, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 646, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\nuno\\AppData\\Local\\Temp\\ipykernel_6484\\3427449114.py\", line 27, in IoU_Own\n      iou = tf.py_function(bb_intersection_over_union, [y_true, y_pred], tf.float32)\nNode: 'EagerPyFunc'\nTypeError: 'DType' object is not callable\nTraceback (most recent call last):\n\n  File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"c:\\Users\\nuno\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\nuno\\AppData\\Local\\Temp\\ipykernel_6484\\3507677061.py\", line 17, in bb_intersection_over_union\n    iou = interArea / tf.float32(boxAArea + boxBArea - interArea)\n\nTypeError: 'DType' object is not callable\n\n\n\t [[{{node EagerPyFunc}}]] [Op:__inference_train_function_118534]"
     ]
    }
   ],
   "source": [
    "my_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='mse',\n",
    "              metrics=IoU_Own)\n",
    "\n",
    "my_model.fit(train_dataset, epochs=2, validation_data=val_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "https://arxiv.org/abs/1512.03385\n",
    "\n",
    "https://www.tensorflow.org/addons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
