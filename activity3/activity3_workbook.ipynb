{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/en/5/5f/Western_Institute_of_Technology_and_Higher_Education_logo.png)\n",
    "\n",
    "**InstitutoTecnológico y de Estudios Superiores de Occidente**\n",
    "\n",
    "**Maestría Ciencia de Datos**\n",
    "\n",
    "**Aprendizaje Profundo**\n",
    "\n",
    "# Actividad 3 #\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* * *\n",
    "\n",
    "Estudiante: Daniel Nuño <br>\n",
    "Profesor: Dr. Francisco Cervantes <br>\n",
    "Fecha entrega: February 12, 2023 <br>\n",
    "\n",
    "* * *\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<div style=\"page-break-after: always;\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre análisis\n",
    "\n",
    "Creo que el uso de imágenes segmentas da una ligera ventaja ya que el fondo es negro, resalta la hoja, y la enfermedad. El primer paso es importar las imágenes:\n",
    "\n",
    "- recesivamente importar las imágenes de la carpeta *segmented*.\n",
    "    - primero intentar con escala de grises y después a color.\n",
    "- cambiar el tamaño para que sea más manejable.\n",
    "    - primero intentar con el tamaño original, después reduciendo el tamaño.\n",
    "- rotar la matriz 90 grados 3 veces con la intención de generar 3 veces más datos.\n",
    "- aplanarlos para tener una matriz de cuatro observaciones.\n",
    "- usar el nombre de la carpeta para obtener las clasificaciones: tipo de hoja y estado de salud.\n",
    "\n",
    "La matriz X esperada es:\n",
    "\n",
    "- 56,304 x 4 = 225,216 filas\n",
    "- dependiendo de la forma de importar de las imágenes X cantidad de columnas\n",
    "\n",
    "La matriz Y esperada es:\n",
    "\n",
    "- misma cantidad de filas que X\n",
    "- 14 columnas por la especie más 26 columnas por enfermedades = 40 multiclase y multi clasificación.\n",
    "    - 38 siendo la combinación de ambas. Tratar el modelo así tiene ventaja de ser solo multiclase.\n",
    "\n",
    "Para la evolución de modelos será iterativo, modificando los hyperpárametros manualmente para entender cómo afectan el modelo. Pocos datos y pocas épocas para entrenar con el modelo cuando este decidido cual dirección pareciera ser el mejor.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear conjunto de datos a partir de la estructura de carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "main_folder_path = 'C:/Users/nuno/Desktop/deep-learning-data/activity3/' + 'segmented/'\n",
    "\n",
    "counter = 0\n",
    "metadata_img = []\n",
    "r_size = 28\n",
    "arr = np.zeros((54306*4, r_size, r_size, 3)) #32*32*1 img size // 54306 * 4 rotations\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(main_folder_path):\n",
    "    for filename in filenames:\n",
    "        dirs_paths_state = [#os.path.join(dirpath, filename), #image full directory\n",
    "                            str(os.path.basename(dirpath)).split('___')[0], #fruit\n",
    "                            str(os.path.basename(dirpath)).split('___')[1] #state\n",
    "                            ]\n",
    "        img = Image.open(os.path.join(dirpath, filename)) #open image\n",
    "        #img = img.convert('L') #convert to greyscale\n",
    "        if img.getbands() == ('L',):\n",
    "            img = img.convert('RGB') #convert to rgb to keep 3 channels if read as greyscale\n",
    "        img = img.resize((r_size, r_size)) #resize\n",
    "\n",
    "        for times in range(4):\n",
    "            metadata_img.append(dirs_paths_state) #Y array\n",
    "            arr[times + (counter*4)] = np.array(img)/255 #X array\n",
    "            #arr[times + (counter*4)] = np.ravel(np.array(img)) #X array\n",
    "            img = img.rotate(angle=90) #rotate image to generate\n",
    "        \n",
    "        counter += 1\n",
    "\n",
    "img.close() #close connection\n",
    "\n",
    "arr = arr.astype(np.float16)\n",
    "metadata_img = np.array(metadata_img, dtype=str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear conjunto de entrenamiento, prueba y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217224, 38)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "Y = np.char.add(metadata_img[:,0], metadata_img[:,1])\n",
    "print((len(Y), len(set(Y))))\n",
    "\n",
    "dummy_encoder_state = OneHotEncoder(sparse=False)\n",
    "dummy_encoder_state.fit(Y.reshape(-1,1))\n",
    "Y = dummy_encoder_state.transform(Y.reshape(-1,1))\n",
    "\n",
    "#one could use:\n",
    "    # tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    # or parse_categorical_crossentropy as loss and sparse_categorical_accuracy as metric\n",
    "#if do not one-hot encode your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21722, 28, 28, 3), (21722, 38))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(arr, Y, test_size=0.9, random_state=27)\n",
    "(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos red neuronal\n",
    "\n",
    "Aunque el entrenamiento es el mismo para los diferentes modelos ajustando los hyperparametros, la red neuronal no es reproducible. Un buen modelo puede ser solo suerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 28, 28, 1)         28        \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 38)                29830     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 38)                1482      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,340\n",
      "Trainable params: 31,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 3)),\n",
    "    Conv2D(1, kernel_size=(3,3), strides=1, padding='same', activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(38, activation=\"relu\"),\n",
    "    Dense(38, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "679/679 [==============================] - 30s 44ms/step - loss: 2.8927 - accuracy: 0.2225\n",
      "Epoch 2/2\n",
      "679/679 [==============================] - 32s 48ms/step - loss: 2.5552 - accuracy: 0.2771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a56479efb0>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model1.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=2,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2\n",
    "\n",
    "Cambio drásticamente tamaño del filtro y kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "679/679 [==============================] - 54s 80ms/step - loss: 2.4745 - accuracy: 0.3291\n",
      "Epoch 2/2\n",
      "679/679 [==============================] - 55s 80ms/step - loss: 1.8187 - accuracy: 0.4768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a563fe7370>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 3)),\n",
    "    Conv2D(8, kernel_size=(6,6), strides=1, padding='same', activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(38, activation=\"relu\"),\n",
    "    Dense(38, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model2.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 28, 28, 8)         872       \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 38)                238374    \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 38)                1482      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 240,728\n",
      "Trainable params: 240,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar un cambio positivo en el accuracy. Aun se puede mejorar la primera capa oculta incrementando las neuronas hasta el tamaño de entrada previo (después de flatten).\n",
    "\n",
    "### Modelo 3\n",
    "\n",
    "Incrementa la primera capa oculta a 6272 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "679/679 [==============================] - 169s 249ms/step - loss: 1.9206 - accuracy: 0.4501\n",
      "Epoch 2/2\n",
      "679/679 [==============================] - 169s 249ms/step - loss: 1.0915 - accuracy: 0.6642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a563ceb1c0>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 3)),\n",
    "    Conv2D(8, kernel_size=(6,6), strides=1, padding='same', activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(6272, activation=\"relu\"),\n",
    "    Dense(38, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model3.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=2,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo mostro mejora pero fue mucho más lento.\n",
    "\n",
    "### Modelo 4\n",
    "\n",
    "Disminuye la cantidad de neuronas de la primera capa y aumenta la cantidad de capas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "679/679 [==============================] - 66s 97ms/step - loss: 2.0437 - accuracy: 0.4123\n",
      "Epoch 2/2\n",
      "679/679 [==============================] - 66s 96ms/step - loss: 1.3098 - accuracy: 0.5996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a561177370>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = keras.Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 3)),\n",
    "    Conv2D(8, kernel_size=(6,6), strides=1, padding='same', activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(1500, activation=\"relu\"),\n",
    "    Dense(750, activation=\"relu\"),\n",
    "    Dense(375, activation=\"relu\"),\n",
    "    Dense(38, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model4.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model4.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=2,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se desempeñó ligeramente peor disminuyendo las neuronas de la primera capa y aumentando las capas ocultas. Fue sin embargo ligeramente más rápido.\n",
    "\n",
    "### Modelo 5\n",
    "\n",
    "Para el último modelo cambiar las funciones de activación en la segunda capa por *sigmoid*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "679/679 [==============================] - 67s 98ms/step - loss: 2.1945 - accuracy: 0.3718\n",
      "Epoch 2/2\n",
      "679/679 [==============================] - 68s 100ms/step - loss: 1.4598 - accuracy: 0.5523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5541cfaf0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 3)),\n",
    "    Conv2D(8, kernel_size=(6,6), strides=1, padding='same', activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(1500, activation=\"sigmoid\"),\n",
    "    Dense(750, activation=\"relu\"),\n",
    "    Dense(375, activation=\"relu\"),\n",
    "    Dense(38, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model5.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model5.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=2,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo tiene un desempeño peor que el modelo 3 y 4 por 10% y 5%. Aunque el modelo 4 tiene peor desempeño que el modelo 3 es más rápido.\n",
    "\n",
    "### Modelo 6\n",
    "\n",
    "Usando como base el modelo 4, cambiar optimizador por *nadam* y *sdg*. (Nadam is Adam, but with Nesterov momentum instead of ordinary momentum. The advantage of using Nesterov momentum instead of regular momentum is the same as it is in the SGD case.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "679/679 [==============================] - 143s 209ms/step - loss: 2.0176 - accuracy: 0.4163\n",
      "Epoch 2/2\n",
      "679/679 [==============================] - 146s 215ms/step - loss: 1.2486 - accuracy: 0.6181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a550c409d0>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = keras.Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 3)),\n",
    "    Conv2D(8, kernel_size=(6,6), strides=1, padding='same', activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(1500, activation=\"relu\"),\n",
    "    Dense(750, activation=\"relu\"),\n",
    "    Dense(375, activation=\"relu\"),\n",
    "    Dense(38, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model6.compile(loss=\"categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "model6.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=2,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nadam el último modelo trabaja bien, pero es casi igual de lento que el modelo 3 pero peor desempeño. SDG es más rápido, pero considerablemente peor.\n",
    "\n",
    "#### AUC de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8881164"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.metrics import AUC\n",
    "\n",
    "y_pred = model1.predict(X_train)\n",
    "auc_validatio1 = AUC()\n",
    "auc_validatio1.update_state(Y_train, y_pred)\n",
    "auc_validatio1.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 25s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95536566"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2.predict(X_train)\n",
    "auc_validatio2 = AUC()\n",
    "auc_validatio2.update_state(Y_train, y_pred)\n",
    "auc_validatio2.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 6s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9831232"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model3.predict(X_train)\n",
    "auc_validatio3 = AUC()\n",
    "auc_validatio3.update_state(Y_train, y_pred)\n",
    "auc_validatio3.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 6s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98561656"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model4.predict(X_train)\n",
    "auc_validatio4 = AUC()\n",
    "auc_validatio4.update_state(Y_train, y_pred)\n",
    "auc_validatio4.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 6s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9774611"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model5.predict(X_train)\n",
    "auc_validatio5 = AUC()\n",
    "auc_validatio5.update_state(Y_train, y_pred)\n",
    "auc_validatio5.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/679 [==============================] - 6s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9700636"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model6.predict(X_train)\n",
    "auc_validatio6 = AUC()\n",
    "auc_validatio6.update_state(Y_train, y_pred)\n",
    "auc_validatio6.result().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados indican que los modelos más confiables, respecto a la curva ROC, son el 3 y 4 por que son los valores más altos.\n",
    "\n",
    "### Modelo 4 con entrenamiento completo.\n",
    "\n",
    "Utilizar el modelo 4 con 80% de los datos y aumentando las epocas a 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178123, 28, 28, 3), (178123, 38))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(arr, Y, test_size=0.18, random_state=27)\n",
    "(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 3)),\n",
    "    Conv2D(8, kernel_size=(6,6), strides=1, padding='same', activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(1500, activation=\"relu\"),\n",
    "    Dense(750, activation=\"relu\"),\n",
    "    Dropout(rate=0.01),\n",
    "    Dense(375, activation=\"relu\"),\n",
    "    Dense(38, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model4.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model4.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=2,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1222/1222 - 10s - loss: 0.8840 - accuracy: 0.7953 - 10s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model4.evaluate(X_test, Y_test, verbose=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy final es de 80%.\n",
    "\n",
    "### Exportar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.save('keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('keras_model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear pipeline\n",
    "\n",
    "Este pipeline asume que las imágenes nuevas no se conoce la clasificación a priori.\n",
    "- La imagen(es) vienen de una misma carpeta.\n",
    "- Las imágenes son segmentadas.\n",
    "- Se necesita Image de PIL, os, y array de numpy.\n",
    "- No sabes cuantas imágenes hay.\n",
    "- El tamaño de la imagen es convertida a 28x28x3.\n",
    "- El modelo ya está construido y con pesos para usar *predict*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder_path = 'C:/Users/nuno/Desktop/deep-learning-data/activity3/' + 'test_pipeline/'\n",
    "\n",
    "keys = ['Apple___Apple_scab', 'Apple___Black_rot',\n",
    "       'Apple___Cedar_apple_rust', 'Apple___healthy',\n",
    "       'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew',\n",
    "       'Cherry_(including_sour)___healthy',\n",
    "       'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
    "       'Corn_(maize)___Common_rust_',\n",
    "       'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy',\n",
    "       'Grape___Black_rot', 'Grape___Esca_(Black_Measles)',\n",
    "       'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy',\n",
    "       'Orange___Haunglongbing_(Citrus_greening)',\n",
    "       'Peach___Bacterial_spot', 'Peach___healthy',\n",
    "       'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy',\n",
    "       'Potato___Early_blight', 'Potato___Late_blight',\n",
    "       'Potato___healthy', 'Raspberry___healthy', 'Soybean___healthy',\n",
    "       'Squash___Powdery_mildew', 'Strawberry___Leaf_scorch',\n",
    "       'Strawberry___healthy', 'Tomato___Bacterial_spot',\n",
    "       'Tomato___Early_blight', 'Tomato___Late_blight',\n",
    "       'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot',\n",
    "       'Tomato___Spider_mites Two-spotted_spider_mite',\n",
    "       'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
    "       'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_new_images(main_folder_path, model_to_predict, keys):\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    results_array = []\n",
    "    class_list = []\n",
    "    files_names_list = []\n",
    "    r_size = 28\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(main_folder_path):\n",
    "        for filename in filenames:\n",
    "            files_names_list.append(os.path.join(dirpath, filename))\n",
    "            \n",
    "            img = Image.open(os.path.join(dirpath, filename)) #open image\n",
    "            #convert to rgb to keep 3 channels if read as greyscale\n",
    "            if img.getbands() == ('L',):\n",
    "                img = img.convert('RGB')\n",
    "            img = img.resize((r_size, r_size)) #resize\n",
    "            arr = np.array(img)/255\n",
    "            arr = np.expand_dims(arr, axis=0)\n",
    "            result_ = model.predict(arr, verbose=0)\n",
    "\n",
    "            results_array.append(result_)\n",
    "            idx = np.argmax(result_)\n",
    "            class_list.append(keys[idx])\n",
    "\n",
    "    img.close() #close connection\n",
    "\n",
    "    return results_array, class_list, files_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1, r2, r3 = pipeline_new_images(test_folder_path, model, keys)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "En conclusión, el modelo parece sobre entrenado por que el accuracy en el entrenamiento es casi 15% mejor que la evaluación con la prueba.\n",
    "El uso correcto de la convolución es más importante que la fuerza bruta. Más parámetros (neuronas y capas ocultas) ayudó a mejor los resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "102a976f0e86ebaac5d44f1c7df09d65d6c14d74209e264d889fb01976a5cf38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
